{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22aaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe\n",
    "# load datasets\n",
    "# initialize dataset class\n",
    "# initialize model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6e79f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.models.ncf import SimpleNCF, DeepNCF\n",
    "from src.training.eval import collect_user_predictions, compute_metrics\n",
    "from src.training.train_mlp import train_model, evaluate_model\n",
    "from src.data.datasets import PointwiseImplicitDataset, OfflineImplicitDataset\n",
    "from src.utils.hparam_search import param_comb\n",
    "from src.data.samplers import GlobalUniformNegativeSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de01fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3815ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.constants import (\n",
    "    DEFAULT_USER_COL as USER,\n",
    "    DEFAULT_ITEM_COL as ITEM,\n",
    "    DEFAULT_TARGET_COL as TARGET,\n",
    "    DEFAULT_TIMESTAMP_COL as TIMESTAMP,\n",
    ")\n",
    "\n",
    "MODEL_TYPE = \"SimpleNCF\"\n",
    "TUNE = False\n",
    "CONFIG = load_config(\"src/config/ncf.yml\")\n",
    "\n",
    "DEVICE = CONFIG[\"system\"][\"device\"]\n",
    "LOCATION = CONFIG[\"data\"][\"location\"]\n",
    "if TUNE:\n",
    "    MODEL_CONFIG = CONFIG[MODEL_TYPE][\"tuning\"]\n",
    "    TRAIN_FILE = \"train\"\n",
    "    TEST_FILE = \"val\"\n",
    "else:\n",
    "    MODEL_CONFIG = CONFIG[MODEL_TYPE][\"optim_params\"]\n",
    "    TRAIN_FILE = \"train_val\"\n",
    "    TEST_FILE = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bdfb90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(f\"{LOCATION}/{TRAIN_FILE}.parquet\")\n",
    "df_test = pd.read_parquet(f\"{LOCATION}/{TEST_FILE}.parquet\")\n",
    "df_interactions = pd.read_parquet(f\"{LOCATION}/interactions.parquet\")\n",
    "\n",
    "user_positive_items = df_interactions.groupby(USER)[ITEM].apply(set).to_dict()\n",
    "\n",
    "n_users = df_interactions[USER].max() + 1\n",
    "n_items = df_interactions[ITEM].max() + 1\n",
    "\n",
    "negative_sampler = GlobalUniformNegativeSampler(n_items, user_positive_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b38768",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparam_combinations = param_comb(config=MODEL_CONFIG, is_tune=TUNE)\n",
    "\n",
    "for hparams in hparam_combinations:\n",
    "    # MERGE: Combine fixed settings with current trial settings\n",
    "    # This ensures 'step_size' and 'gamma' are available\n",
    "\n",
    "    print(f\"Testing: {hparams}\")\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # ------ Model Related Parameters\n",
    "    # ------------------------------------------------------------------------------\n",
    "\n",
    "    EPOCHS = hparams[\"epochs\"]\n",
    "    N_NEGATIVES = hparams[\"n_negatives\"]\n",
    "    BATCH_SIZE = hparams[\"batch_size\"]\n",
    "    N_WORKERS = hparams[\"n_workers\"]\n",
    "    STEP_SIZE = hparams[\"step_size\"]\n",
    "    GAMMA = hparams[\"gamma\"]\n",
    "    LOG_EVERY = hparams[\"log_every\"]\n",
    "    THRESHOLD = hparams[\"threshold\"]\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # ------ Prepare Dataset / Loader\n",
    "    # ------------------------------------------------------------------------------\n",
    "\n",
    "    # data = NCFDataset()\n",
    "\n",
    "    # data.train_dataset\n",
    "    # data.train_loader\n",
    "    # data.test_dataset\n",
    "    # data.test_loader\n",
    "\n",
    "    train_dataset = PointwiseImplicitDataset(\n",
    "        users=df_train[USER].values,\n",
    "        items=df_train[ITEM].values,\n",
    "        timestamps=df_train[TIMESTAMP].values,\n",
    "        negative_sampler=negative_sampler,\n",
    "        n_negatives=N_NEGATIVES,\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, num_workers=N_WORKERS, shuffle=True\n",
    "    )\n",
    "\n",
    "    test_dataset = OfflineImplicitDataset(\n",
    "        users=df_test[USER].values,\n",
    "        items=df_test[ITEM].values,\n",
    "        targets=df_test[TARGET].values,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=BATCH_SIZE, num_workers=N_WORKERS, shuffle=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
